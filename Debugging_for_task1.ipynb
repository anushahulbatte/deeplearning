{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNd3a1vRm1lo8uewcROpsMt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anushahulbatte/deeplearning/blob/main/Debugging_for_task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8To09EUr5fiV",
        "outputId": "37a19588-6a4f-442e-f1f6-348c0dd78a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch is already at the correct version (2.5.1).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.__version__ != '2.5.1+cu124':\n",
        "    !pip install torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124 -U --quiet\n",
        "    print(\"PyTorch version updated to 2.5.1.\")\n",
        "else:\n",
        "    print(\"PyTorch is already at the correct version (2.5.1).\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l==1.0.3 --quiet\n",
        "!pip install scipy --quiet\n",
        "!pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "jQGccqwf5k7O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import RandomSampler, random_split\n",
        "\n",
        "from tqdm.auto import tqdm, trange\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "DEVICE = torch.device(\"mps\")"
      ],
      "metadata": {
        "id": "sdRdoyUo5mPa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "F3iA_bVH5n8Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git\n",
        "os.chdir(\"grs34806-deep-learning-project-data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEQdkxN365HX",
        "outputId": "4447e766-c5c4-4ac5-fd6f-89a2e9e790ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'grs34806-deep-learning-project-data' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing a function to read the simulated data and produce lists containing the sequences and a list of 0s and 1s."
      ],
      "metadata": {
        "id": "pmwhqC2FATO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read(seqfile, posfile):\n",
        "  \"\"\"\n",
        "  Extracting the sequences from the seqfile and creating a list called datalist.\n",
        "  Making a list called labellist containing 0s and 1s, where 1 denotes the\n",
        "  sequence identifiers in the posfile.\n",
        "  \"\"\"\n",
        "  # Removing the sequence identifiers\n",
        "  with open(seqfile, 'r') as f:\n",
        "    seq_lines = [seq_lines.strip() for seq_lines in f.readlines() if seq_lines.strip()]\n",
        "    #print(seq_lines)\n",
        "  seq_ids = []\n",
        "  datalist = []\n",
        "  current_seq = \"\"\n",
        "  for line in seq_lines:\n",
        "    if line.startswith(\"seq\"):\n",
        "      parts = line.split()\n",
        "      #print(parts)\n",
        "      seq_ids.append(parts[0])\n",
        "      datalist.append(parts[1])\n",
        "\n",
        "  with open(posfile, 'r') as f:\n",
        "    annotated_ids = [line.strip() for line in f.readlines() if line.strip()]\n",
        "    #print(annotated_ids)\n",
        "  labellist = [1 if seq_id in annotated_ids else 0 for seq_id in seq_ids]\n",
        "  #print(labellist)\n",
        "  assert len(datalist) == len(labellist) == len(seq_ids), \"Lengths of lists don't match\"\n",
        "\n",
        "  print(\"Length of the datalist: \", len(datalist))\n",
        "  print(\"Length of labellist: \", len(labellist))\n",
        "  print(\"The number of positives in labellist: \", sum(labellist))\n",
        "  for i in range(min(5, len(datalist))):\n",
        "        print(f\"ID: {seq_ids[i]}, Has annotation: {labellist[i]}, Sequence length: {len(datalist[i])}\")\n",
        "\n",
        "  return datalist, labellist\n"
      ],
      "metadata": {
        "id": "TuiXJEqM7VyX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(seqfile = \"/content/grs34806-deep-learning-project-data/len100_200_n1000.seq\",\n",
        "posfile = \"/content/grs34806-deep-learning-project-data/len100_200_n1000.pos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y4_oi5xAH0N",
        "outputId": "39c95a80-0115-449d-f4bb-c382be63780d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the datalist:  1000\n",
            "Length of labellist:  1000\n",
            "The number of positives in labellist:  507\n",
            "ID: seq1, Has annotation: 1, Sequence length: 113\n",
            "ID: seq2, Has annotation: 0, Sequence length: 166\n",
            "ID: seq3, Has annotation: 0, Sequence length: 197\n",
            "ID: seq4, Has annotation: 1, Sequence length: 150\n",
            "ID: seq5, Has annotation: 0, Sequence length: 134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the lists into training and testing datasets using the train_test_split method from sklearn."
      ],
      "metadata": {
        "id": "-6wiBFSQBwXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_train_test (datalist, labellist):\n",
        "  traindatalist, testdatalist, trainlabellist, testlabellist = train_test_split(\n",
        "      datalist, labellist, test_size=0.2, random_state=42\n",
        "  )\n",
        "  return traindatalist, testdatalist, trainlabellist, testlabellist"
      ],
      "metadata": {
        "id": "2Nszbu4VB3La"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindatalist, testdatalist, trainlabellist, testlabellist = generate_train_test(\n",
        "    datalist, labellist\n",
        ")\n",
        "# Printing the length of the training and testing data\n",
        "print(\"Training data size:\", len(traindatalist))\n",
        "print(\"Training labels size:\", len(trainlabellist))\n",
        "print(\"Test data size:\", len(testdatalist))\n",
        "print(\"Test labels size:\", len(testlabellist))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SUP0QnkC9Gk",
        "outputId": "b6b58646-213d-41be-ea30-d876e0a7d172"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data size: 800\n",
            "Training labels size: 800\n",
            "Test data size: 200\n",
            "Test labels size: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defined the provided functions."
      ],
      "metadata": {
        "id": "frMYmACTD5oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(dat, map2num, non_aa_num=20):\n",
        "  \"\"\"\n",
        "  This function takes in the sequences of AA. It uses dictionary mapping, to map\n",
        "  AA to integers. The non_aa_num make up the unknown AA, and its default value is\n",
        "  20.\n",
        "  \"\"\"\n",
        "  seq = []\n",
        "  for count, i in enumerate(dat):\n",
        "      seq.append([map2num.get(j, non_aa_num) for j in list(i)])\n",
        "  return seq"
      ],
      "metadata": {
        "id": "xd4QzzKcD7za"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_seq_array(lines, num_steps, non_aa_num=20):\n",
        "  \"\"\"\n",
        "  This function applies the truncate_pad function to all the sequences.\n",
        "  It then converts the sequences into tensors.\n",
        "  \"\"\"\n",
        "  array = torch.tensor([\n",
        "      truncate_pad(l, num_steps, non_aa_num) for l in lines])\n",
        "  return array"
      ],
      "metadata": {
        "id": "X02QA1bBECPn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_pad(line, num_steps, padding_token):\n",
        "  \"\"\"\n",
        "  The line in the parameters refers to the tokenized sequence.\n",
        "  num_steps is the maxmimum sequence length. The padding_token is the integer\n",
        "  for padding.\n",
        "  The function pads shorter sequences with padding_token.\n",
        "  \"\"\"\n",
        "  if len(line) > num_steps:\n",
        "    return line[:num_steps] #Truncate\n",
        "  return line + [padding_token] * (num_steps - len(line))"
      ],
      "metadata": {
        "id": "5-HWJ2LHEF67"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "LWA5mwdKEXTM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function also includes code for converting the tokenized seq into a 1-hot encoded representation so it can be fed as input to the CNN."
      ],
      "metadata": {
        "id": "xzVm8qtlEd9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(batch_size, num_steps, dataset, trainlabels = None):\n",
        "  mapaa2num = {aa: i for (i, aa)\n",
        "                      in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
        "  # Creating a dictionary which maps each AA to a unique integer\n",
        "  seq, lab = dataset, trainlabels # lab is the labels which are associated with sequences\n",
        "\n",
        "  seq = tokenize(seq, mapaa2num)\n",
        "  seq_array = build_seq_array(seq, num_steps) # Shape = batch_size, num_steps\n",
        "\n",
        "  # To convert the sequences to one-hot encoding\n",
        "  # one_hot method takes a tensor and returns a tensor of shape of num_classes\n",
        "  vocab_size = len(mapaa2num)\n",
        "  seq_onehotencoding = F.one_hot(seq_array, num_classes=vocab_size).float()\n",
        "  seq_onehotencoding = seq_onehotencoding.permute(0,2,1)\n",
        "  # Shape = batch_size, vocab_size, num_steps\n",
        "\n",
        "  data_arrays = (seq_onehotencoding, torch.tensor(lab))\n",
        "  data_iter = d2l.load_array(data_arrays, batch_size)\n",
        "  print(\"Shape of seq_array: \", seq_array.shape)\n",
        "  print(\"Shape of data_arrays, which now considers \\none-hot encoded sequence: \",\n",
        "        seq_onehotencoding.shape)\n",
        "  return data_iter"
      ],
      "metadata": {
        "id": "BG2KQGODEYOA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = load_data(batch_size = 25, num_steps=50, dataset=traindatalist, trainlabels=trainlabellist)\n",
        "test_iter = load_data(batch_size= 25, num_steps = 50, dataset = testdatalist, trainlabels = testlabellist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJAkycyAFCaI",
        "outputId": "5a87a363-5bda-4d4b-9ec8-8570c2f1dd04"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of seq_array:  torch.Size([800, 50])\n",
            "Shape of data_arrays, which now considers \n",
            "one-hot encoded sequence:  torch.Size([800, 20, 50])\n",
            "Shape of seq_array:  torch.Size([200, 50])\n",
            "Shape of data_arrays, which now considers \n",
            "one-hot encoded sequence:  torch.Size([200, 20, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the 1D-CNN model."
      ],
      "metadata": {
        "id": "LeZNd6ClFviS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProteinCNN1D(nn.Module):\n",
        "  def __init__(self, vocab_size:int, context_size:int, conv_channels:int=128,\n",
        "                use_bias:bool=False):\n",
        "      super().__init__()\n",
        "      assert context_size % 2 == 0, f'Invalid block_size, {context_size} is not an even number'\n",
        "      self.vocab_size = vocab_size\n",
        "      self.context_size = context_size\n",
        "      self.cnn = nn.Sequential(\n",
        "          nn.Conv1d(in_channels=self.vocab_size,\n",
        "                    out_channels=conv_channels,\n",
        "                    kernel_size=3,\n",
        "                    padding='same',\n",
        "                    bias=use_bias),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool1d(kernel_size = 2, stride = 2),\n",
        "\n",
        "          nn.Conv1d(in_channels=conv_channels,\n",
        "                    out_channels=conv_channels,\n",
        "                    kernel_size = 3,\n",
        "                    padding = 'same',\n",
        "                    bias = use_bias),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool1d(kernel_size = 2, stride = 2),\n",
        "\n",
        "          nn.Flatten(1, -1),\n",
        "          nn.Linear(in_features = int(conv_channels*self.context_size/4),\n",
        "                    out_features = 1,\n",
        "                    bias = use_bias)\n",
        "\n",
        "      )\n",
        "      def forward(self, X:torch.tensor, targets: torch.tensor=None) -> tuple[torch.tensor, torch.tensor]:\n",
        "        logits = self.cnn(X).squeeze(1)\n",
        "        loss = None if targets is None else F.binary_cross_entropy_with_logits(\n",
        "            logits, targets.float())\n",
        "        return logits, loss\n",
        "\n"
      ],
      "metadata": {
        "id": "2udPUCghFy27"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}